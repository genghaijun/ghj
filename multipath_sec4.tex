
\section{Performance Evaluation}\label{evaluation}
Since our main motivation is to achieve good computational efficiency and LFA coverage,
we compare IAC with TBFH, DMPA, and the naive method that computes $k$ SPT (denoted by Naive in the graphs).
Table \ref{comptable} lists their capabilities of computing alternate next hops
with respect to each criterion,
where ``$full$'' means the corresponding algorithm can compute all alternate next hops
that satisfy the LFA criterion in the column header, ``$partial$'' means only a subset
of alternate next hops for the criterion can be computed, while ``$-$'' means the algorithm
cannot be used for that criterion.  IAC and the naive method support all the three criteria and
computes all the next hops.
DMPA and TBFH, on the other hand, can compute a subset of next hops for \textbf{LFC}
and \textbf{DC} only.



\begin{table}[h]
\caption{Comparison of different algorithms}
\label{comptable}
\centering
%\large
\normalsize
\begin{tabular}{|c|c|c|c|c|c|c|}% 通过添加 | 来表示是否需要绘制竖线
\hline  % 在表格最上方绘制横线
Algorithm&LFC&NPC&DC\\
\hline
Naive&$full$&$full$&$full$\\
\hline
DMPA&$partial$&$-$&$partial$\\
\hline
TBFH&$partial$&$-$&$partial$\\
\hline % 在表格最下方绘制横线
IAC&$full$ &$full$&$full$\\
\hline % 在表格最下方绘制横线
\end{tabular}

\end{table}




\iffalse
Evaluation studies \cite{Gjoka2007Evaluation,Menth20101300} show that LFA protects against
many more failures than ECMP. Nevertheless, they also reveal that, on
average, LFA offers protection against only about 50\%
of all possible link failures and less than 40\% of node failures
Despite the limited protection it achieves, LFA is already supported by some equipment vendors \cite{cisco,Juniper}. With that in mind,
Retvari et al. \cite{lfarevisited} suggested that networks should be augmented with additional links to ensure that LFA can provide recovery
for all possible failures.
Therefore, our algorithms can directly use the above research findings, so that they can protect all single network component failure scenarios in the network.
\fi

We evaluate the performance of these algorithms in the following three types of topologies:
\begin{itemize}
\item [(1)] Topologies published by ISPs, including Cernet2, Abilene, Njlata, Toronto, and Usld.
\item [(2)] Network topologies inferred by measurement studies\cite{2004148100061},
including AS1221, AS1239, AS1755, AS3257, AS3967, and AS6461.
\item [(3)] Synthetic topologies generated by a random graph generator BRITE\cite{medina2001brite}.
\end{itemize}

The topology sizes of the published and inferred topologies vary from 11 to to 315,
and the average node degrees vary from 1.14 to 3.09, while in the synthetic topologies,
the sizes and degrees are set to be from 20 to 500, and from 5 to 25, respectively.
We note that a much larger topology size or node degree exists in practice,
i.e., there exist networks with thousands of nodes, or routes with hundreds of neighbors,
but our evaluation on the topologies above are already enough to demonstrate
the gap between IAC and the other algorithms.

\iffalse
Cernet2 (14 nodes, 16 links), Abilene (11 nodes, 14 links), Njlata (11 nodes, 23 links), Toronto (25 nodes, 55 links) and
Usld (28 nodes, 45 links)
and five ISP topologies which are measured by Rocketfuel\cite{2004148100061},
including   AS1221 (108 nodes, 153 links),
AS1239 (315 nodes, 972 links),
AS1755 (87 nodes, 161 links), AS3257 (161 nodes, 328 links),
AS3967 (79 nodes, 147 links), and AS6461  (128 nodes, 372 links) .
We also generate synthetic topologies with BRITE \cite{medina2001brite}.
The model is set to Waxman, mode is set to be Router only. The bandwidth
on each link follows a heavy-tail distribution ranging from
100 to 1024 \cite {Gjoka2007Evaluation} and the link cost is an inverse function of the bandwidth.
The parameters $\alpha$ and $\beta$ are set to 0.5.
%using parameters as listed in Table \ref{britetable}.
%In this section, we first show how link failures are modeled in our evaluation.

For similarity, we use a simple model to characterize link failure events.
The fail probability of each link $e$
is randomly generated in the range from 0 to 0.001.
All the simulations are conducted on a PC with Intel
i5 CPU, 1.7GHz and 1.5G Memory.

Due to space
constraints, we only present the results
for DC rule in the experiment, while the results for LFC and NPC
are similar.
\fi
%Because neither DMPA nor TBFH can implement the NPC rule,  so in the experiment we only compare the performance of the four methods on achieving  DC rule.

%Due to space constraints, we only list data for DC rules.
%Because neither DMPA nor TBFH can implement the NPC rule, IAC can only implement DC rule, so in the experiment we only compare the performance of
%the four methods on achieving  DC rule.

%Because IAC and IAC-NA have similar performance in realizing DC rule, IAC/IAC-NA is used to represent these two algorithms in the following section.
%In the following section, we will use IAC/IAC-NA to denote the IAC and IAC-NA.
\iffalse
\begin{table}[h]
%% increase table row spacing, adjust to taste
\normalsize
\renewcommand{\arraystretch}{1}
\caption{Parameters for BRITE}
\label{britetable}
\begin{center}
\begin{tabular}{c|c|c|c}
\hline
Model& N &   HS & LS  \\
\hline
Waxman & 20-1000&1000&100\\
\hline
\hline
m&NodePlacement &GrowthTypem & ${alpha}$  \\
\hline
2-40 & Random&Incremental&0.5\\
\hline
\hline
 ${beta}$ & BWDist &BwMin &BwMax \\
 \hline
0.5&Heavy Tail&100.0&1024.0\\
\hline
\end{tabular}
\end{center}
\end{table}
\fi


\subsection{Computation overhead}


\begin{figure*}[t!]
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{topcomputationoverhead}
                \caption{Varying topology size in Brite topologies}
              \label{topcom}
        \end{subfigure}
        \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{degcomputationoverhead}
                \caption{Varying node degree in Brite topologies}
                \label{nodedegreecom}
        \end{subfigure}
         \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{realcomputationoverhead}
                \caption{In real network topologies}
                \label{realtopologytime}
        \end{subfigure}
        \caption{Computation complexity in different topologies}
        \label{comoverhead}
\end{figure*}



\iffalse
\begin{figure}[t]
\centering
\includegraphics[width=3in]{degcomputationoverhead}
\caption{Computation overhead on generated topologies when topology size is 200}
\label{nodedegree6}
\end{figure}
\begin{figure}[t]
\centering
\includegraphics[width=3in]{realcomputationoverhead}
%\includegraphics[width=3in]{lfaexample}
\caption{Computation overhead on real and measured topologies}
\label{realtopologytime}
\end{figure}
\fi
\iffalse
Theoretical analysis has indicated that the time complexity of IAC is less than that of building of a shortest path tree, which has a great advantage over Naive, TBFH and DMPA.
In order to verify the computational performance, we make simulations on different topologies. In this section, we evaluate the computational overhead of different algorithms. In order to avoid the uncertain factors impact the algorithm’s performance. The computational overhead of an algorithm is defined as the ratio of computation time of the algorithm to that of SPF (shortest path first).
\fi
First, we compare the computational complexity of these algorithms
by recording the CPU time consumed by each of them, for different topologies.
%Fig. \ref{comoverhead} depicts the CPU time consumed by each algorithm for different topologies.
In Fig. \ref{topcom}, we increase the number of nodes in the synthetic topologies generated by BRITE from 20 to 200,
with an average node degree of 6,
and plot the computing time (y axis) in log scale. We can clearly see IAC outperforms all other
algorithms, by at least an order of magnitude faster.
Actually, the naive method performs $k$ SPT constructions,
TBFH approximately constructs two SPTs, while DMPA constructs exactly one SPT.
This can be verified by plotting the relative ratio of the CPU time
consumed by each algorithm and the standard SPF algorithm, as shown in Fig. \ref {nodedegreecom},
with 500 nodes and an average degree from 5 to 25.
We can see IAC always runs faster than SPF (which is also represented by DMPA) for around 3 times.
In Fig. \ref{realtopologytime}, their performance (with respect to SPF) on real world topologies are compared, where
we see a similar effect. IAC often outperforms the naive method by an order of magnitude,
and outperforms DMPA  by around 3 times.

\iffalse
\begin{figure}[t]
\centering
\includegraphics[width=3in]{rocketcomputationoverhead}
%\includegraphics[width=3in]{lfaexample}
\caption{Computation overhead on  measured topologies}
\label{rockettopologytime}
\end{figure}

Fig. \ref{topcom} shows relationship between the computation overhead and topology size on generated topologies when the average node degree is 6.
Fig. \ref{nodedegreecom} presents the relationship between the computation overhead and average node degree on generated topologies when the topology size is 500.
As the average node degree increases, the computation overhead of Naive increases accordingly. And also IAC has the highest performance among all the algorithms. Therefore, the above experiment results are consistent with the theoretical analysis described above.

Fig. \ref{realtopologytime} indicates the computational overhead obtained by different algorithms on real and Rocketfuel topologies. From the Fig. \ref{realtopologytime}, we can see that IAC has the lowest computation overhead among all the algorithms. The computation overhead of IAC is less than computing a SPT, while DMPA need to construct a SPT and TBFH need to compute two SPTs. The computation overhead of Naive is proportionally to the average node degree of the network.

\begin{figure}[t]
\centering
\includegraphics[width=3in]{tscomputationoverhead}
\caption{Computation overhead on generated topologies when average node degree is 6}
\label{topologysize200}
\end{figure}
\fi


\iffalse
\begin{figure*}[t]
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics{abilenedeploy}
                \caption{$T_{c}$}
              \label{spttree}
        \end{subfigure}
        \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics{exodusdeploy}
                \caption{$T'_{c}$ when $L(c,a)=0$}
                \label{spttreechange1}
        \end{subfigure}
         \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics{sprintdeploy}
                \caption{$T'_{c}$ when $L(c,b)=0$}
                \label{spttreechange2}
        \end{subfigure}
        \caption{An example for explaining some Theorems}
        \label{theoremexample}
\end{figure*}
\fi
\iffalse
\begin{figure}[t]
\centering
\includegraphics[width=3in]{abilenedeploy}
\caption{Incremental Deployment on Abilene}
\label{abilene}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=3in]{exodusdeploy}
\caption{Incremental Deployment on Exodus}
\label{exodus}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=3in]{sprintdeploy}
\caption{Incremental Deployment on Sprint}
\label{sprint}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=3in]{top1000}
\caption{Incremental Deployment on Generated Topologies When Topology Size=1000}
\label{top100avi}
\end{figure}
\fi
\iffalse
\begin{figure}[t]
\centering
\includegraphics[width=3in]{topodeploy200}
\caption{Incremental Deployment on Topology=200}
\label{abilene}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=3in]{topodeploy500}
\caption{Incremental Deployment on Topology=500}
\label{exodus}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=3in]{topodeploy1000}
\caption{Incremental Deployment on Topology=1000}
\label{sprint}
\end{figure}
\fi
\iffalse
Fig. \ref{topologysize200} illustrates the relationship between the computation overhead and topology size on generated topologies when the average node degree is 6. As Fig. \ref{topologysize200} shows, the computation overhead of all the algorithms does not depend on the topology size. The computation overhead of IAC is lowest among all the algorithms.
\fi


\iffalse
 \begin{table}[h]
\centering
\renewcommand{\arraystretch}{1}
\caption{Computation time for Real Topologies}
\label{comparison}
\begin{tabular}{c|c|c|c|c|c|c}
\hline
&\multirow{2}{*}{Network}& \multicolumn{5}{|c}{Computation time ($\upmu$s)} \\
\cline{3-7}
& & OSPF &LFC & TBFH & MNP&MNP-e\\
\hline
Real& Abilene& 6.82&7.27 & 6.97 & 6.83&6.52\\
\hline
\multirow{3}{*}{Measured}& Exodus & 44.36 &128.29&88.76&50.23 &42.34\\
\cline{2-7}
& Telstra & 49.45 &163.43&100.34&54.34&46.23 \\
\cline{2-7}
& Tiscali & 79.45 &398.34&183.56&83.45 &75.34\\
\cline{2-7}
& Sprint &  140.23&906.78 &368.12 & 150.12 &137.34\\
\hline

\end{tabular}
\end{table}
\fi
\subsection{Alternate Next Hops}
Next, we compare the alternate next hops each algorithm can compute.
As we have described earlier in Table \ref{comptable},  \textbf{NPC} cannot be applied to DMPA and TBFH,
while IAC and the naive method compute exactly the same results,
so we plot the results of  DMPA and  TBFH for \textbf{DC},
as well as IAC for \textbf{DC} and \textbf{NPC}.
The corresponding results for \textbf{LFC} are similar to those for \textbf{DC},
and we  omit them in the graphs.

\begin{figure*}[t!]
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{topnum}
                \caption{Varying topology size in Brite topologies}
              \label{topnumber}
        \end{subfigure}
        \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{generatenum}
                \caption{Varying node degree in Brite topologies}
                \label{degnumber}
        \end{subfigure}
         \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{realnum}
                \caption{In real network topologies}
                \label{realnumber}
        \end{subfigure}
        \caption{Average number of alternate next hops in different topologies}
        \label{nexthop}
\end{figure*}

\begin{figure*}[t!]
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{CERNET2cumulative}
                \caption{Cernet2}
              \label{CERNET2cumulative}
        \end{subfigure}
        \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{TORONTOcumulative}
                \caption{Toronto}
                \label{TORONTOcumulative}
        \end{subfigure}
         \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{1239cumulative}
                \caption{AS1239}
                \label{1239cumulative}
        \end{subfigure}
        \caption{Cumulative  distribution of the number of backup next hops on real topologies}
        \label{cumulativedist}
\end{figure*}
\iffalse
\begin{figure}[h]
\centering
\includegraphics[width=3in]{TORONTOcumulative}
\caption{Cumulative  distribution of the number of backup next hops on Toronto topology}
\label{TORONTOcumulative}
\end{figure}
\begin{figure}[h]
\centering
\includegraphics[width=3in]{1239cumulative}
\caption{Cumulative  distribution of the  number of backup next hops on AS1239 topology}
\label{1239cumulative}
\end{figure}
\fi

Fig. \ref{nexthop} depicts, for different topologies,
the average number of alternate next hops (excluding the default one)
that each algorithm can compute for each destination in a topology.
The result of IAC for \textbf{DC} and for \textbf{NPC} are plotted individually,
and are indicated by IAC(DC) and IAC(NPC) respectively. Similar to the complexity graph,
the first subfigure  shows the results for synthetic topologies of size from 20 to 200
with an average node degree of 6, the second one for synthetic topologies
with 500 nodes and an average degree from 5 to 25, and the last one for real topologies.
The results demonstrate the correctness of our conclusion in Table \ref{comptable}.
We can see typically IAC outperforms the other two algorithms by at least 50\%, in both
synthetic and real topologies. And as stated by Geng, et al.\cite{dmpa}, DMPA outperforms TBFH.
In most time, more next hops satisfy \textbf{NPC} than \textbf{DC}, while occasionally
the opposite.

To further understand how great the difference will be on individual nodes,
we plot the cumulative distribution of the number of alternate next hops for some real topologies
in Fig.\ref{cumulativedist}. For example, in AS1239, when using IAC(NPC) or IAC(DC),
around 60\% nodes can find at least one alternate next hop, and around 10\% nodes can find at least
five alternates. However, if DMPA is used, only around 35\% and 1\% nodes can find at least one
and five alternates, respectively. TBFH performs the worst, as only 26\% nodes can find one alternate,
and no node can find a second alternate.

\iffalse
Fig. \ref{topnumber} shows the average number of backup next hops obtained by different algorithms on generated topologies when the average node degree is 6.
Fig. \ref{degnumber} shows the average number of backup next hops obtained by different algorithms on generated topologies when the topology size is 500.
Fig. \ref{realnumber} depicts  the average number of backup next hops obtained by different algorithms on real and measured topologies.
Fig. \ref{CERNET2cumulative}, \ref{TORONTOcumulative} and  Fig. \ref{1239cumulative} show
the cumulative distribution of the  number of backup next hops for CERNET2 , TORONTO and AS1239 topologies.
\fi

\subsection{Protection ratio}

\begin{figure*}[t]
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{protectionratiotop}
                \caption{Varying topology size in Brite topologies}
              \label{prtop}
        \end{subfigure}
                 \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{protectionratiodegree}
                \caption{Varying node degree in Brite topologies}
                \label{prd}
        \end{subfigure}
         \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{protectionratioreal}
                \caption{In real network topologies}
                \label{prreal}
        \end{subfigure}
        \caption{Protection ratio in different topologies}
        \label{protect}
\end{figure*}
\begin{figure*}[t]
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{topavi}
                \caption{Varying topology size in Brite topologies}
              \label{avitop}
        \end{subfigure}
                 \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{degavi}
                \caption{Varying node degree in Brite topologies}
                \label{avideg}
        \end{subfigure}
         \begin{subfigure}[b]{0.32\textwidth}
                \centering
                \includegraphics[width=\textwidth]{realavi}
                \caption{In real network topologies}
                \label{avireal}
        \end{subfigure}
        \caption{Unavailability  of the network in different topologies}
        \label{avi}
\end{figure*}
Now we study how good each algorithm can protect nodes from failures by employing alternate next hops it can find.
We define the protection ratio as
\[
Pr={\sum\limits_{c,d\in V, c\neq d}{K(c,d)}}/{(|V|*(|V|-1))},
\]
where $K(c,d)$ indicates whether any alternate next hop can be found on node $c$ for destination $d$. If node $c$ to node $d$ has at least one alternate next hop (default next hop is excluded) then $K(c,d)=1$, otherwise
$K(c,d)=0$.
\iffalse
\[
K(c,d)=\begin{cases}
1&\mbox{ }\\
0&\mbox{else}
\end{cases}
\]
\fi
Since IAC always finds more alternates, it provides better protection than DMPA and TBFH.
As shown in Fig. \ref{protect}, for example, in the synthetic topology with 500 nodes and an average
node degree of 40, IAC(NPC) nearly provides a protection ratio of 100\%, while DMPA and TBFH
can only provide around 85\% protection ratio. In topologies of real networks, IAC typically
provides a protection ratio of 10\% $\sim$ 20\% greater.

\iffalse
Fig. \ref{prtop} shows relationship between the computation overhead and topology size on generated topologies when the average node degree is 6.
Fig. \ref{prd} presents the relationship between the protection ratio and average node degree on generated topologies
when the topology size is 500.
Fig. \ref{prreal} depicts the protection ratio obtained by different algorithms on real and measured topologies.

\begin{figure}[t]
\centering
\includegraphics[width=3in]{protectionratiodegree}
\caption{Protection ratio on generated topologies when topology size is 200}
\label{prd}
\end{figure}
\begin{figure}[t]
\centering
\includegraphics[width=3in]{protectionratioreal}
\caption{Protection ratio on real and measured topologies}
\label{prreal}
\end{figure}
\fi
\iffalse
\begin{figure}[t]
\centering
\includegraphics[width=3in]{protectionratiorocket}
\caption{Protection ratio on measured topologies}
\label{prrocket}
\end{figure}
\fi
\iffalse
\begin{figure}[t]
\centering
\includegraphics[width=3in]{generatenum}
\caption{Average number of backup next hops on real and measured topologies}
\label{generatenumber}
\end{figure}
\begin{figure}[t]
\centering
\includegraphics[width=3in]{realnum}
\caption{Average number of backup next hops on real and measured topologies}
\label{realnumber}
\end{figure}
\fi
\iffalse
\begin{figure}[t]
\centering
\includegraphics[width=3in]{rocketnum}
\caption{Average number of backup next hops on measured topologies}
\label{rocketnumber}
\end{figure}
\fi



\iffalse
We made several conclusions. First, IAC is more
flexible than TBFH and DMPA. It has more deflection choices in all
the experiment networks. Second, the
larger networks can provide more opportunities to detour.

Last,
For IAC/IAC-NA and DC, more than
40\% of routers have more than one next hop in all simulated topologies.
and this advantage is more pronounced in large topologies.
From Fig. \ref{prreal}, Fig. \ref{prrocket} and Fig. \ref{prd}, we can see that INC, INC-NA and DC have the similar protection ratio, which have better performance than both of DMPA and TBFH.
\fi
\subsection{Network availability}


\iffalse
\begin{figure}[t]
\centering
\includegraphics[width=3in]{topavi}
\caption{Network availability on generated topologies when average node degree=6}
\label{avtop}
\end{figure}
\begin{figure}[t]
\centering
\includegraphics[width=3in]{nodedegree}
\caption{Network availability on generated topologies when topology size=500}
\label{avdeg}
\end{figure}
\fi
In the last, we evaluate how LFAs can protect applications
based on another metric,  network availability \cite{Geng2017Algebra}.
For similarity, we use a simple
model to characterize link failure events. The fail probability of
each link in the network is randomly generated in the range from 0 to 0.01.
The corresponding results for \textbf{LFC}  are similar to those for \textbf{DC}, and we  omit them in the graphs.
In Fig. \ref{avi},  the unavailability (y axis) is equal to that of 1-network availability.
Fig. \ref{avitop} shows the  relationship between the network availability and the topology size when the average node degree is 4.
Fig. \ref{avideg} illustrates the relationship between the network availability and the average node degree  when the topology size is 1000.
Fig. \ref{avireal} presents network availability in real networks.
From Fig. \ref{avi}, we can see the network availability of IAC is close to 100\% in all simulated topologies, while DMPA and TBFH can only
provide around 95\% $\sim$ 99\% network availability.
As shown in the Fig. \ref{avideg}, as the average node degree increase, the network availability increases too. IAC also has a clear advantage over TBFH and DMPA, and has the same performance as Naive.
\iffalse
Since both of the above two metrics cannot accurately describe end-to-end network availability. Therefore, we will use network availability \cite{Geng2017Algebra} to measure the end-to-end availability of different algorithms in the next section.
\fi
\iffalse
 We formally define the network availability $A(G)$ as follows (similar to that in \cite{ReliabilityAnalysis}),
and use it as a main metric to evaluate the protection capability of different schemes.

The end-to-end availability of a source-destination ($s$-$d$) pair is defined as the
probability that the packets can be correctly forwarded from $s$ to $d$.
Assume that there exist $n$ different forwarding paths from $s$ to $d$,
the $i$-th which is denoted by $p_{i}(s,d)$.
We also use $P_{i}(s,d)$ to represent the set of links on the $p_{i}(s,d)$.
Further, let the event that $p_{i}(s,d)$ works be denoted by $A_{i}(s,d)$,
whose probability can be expressed as:
\begin{equation}\label{ir}
P(A_{i})=\prod\limits_{\forall (m,n) \in P_{i}(s,d)}{r(m,n)}
\end{equation}


According to the Inclusion-Exclusion principle \cite{feller},
the end-to-end availability of a source-destination pair can be expressed as:

\begin{equation}\label{asd}
A(s,d)=\sum\limits_{k=1}^{n}{(-1)^{(k-1)}S_k}
\end{equation}
where $S_k$ denote the sum of the probabilities that a unique set of $k$ paths
from $s$ to $d$ are simultaneously working, which is further expressed as:

\begin{eqnarray}\label{sk}
S_{k}&=&\sum\limits_{i<j< \cdots <k}{P(A_{i} \cap A_{j}\cdots \cap A_{k})} \nonumber \\
&=&\sum\limits_{i<j< \cdots <k} \left(\prod\limits_{ (m,n) \in P_{i}(s,d) \cup P_{j}(s,d) \cup \dots \cup P_{k}(s,d)}{r(m,n)}\right) \nonumber
\end{eqnarray}


Then, the network availability can be computed as

\begin{equation}
A(G)=\frac{\sum\limits_{s,d \in V, s \neq d}{A(s,d)}}{|V|*(|V|-1|)}
\end{equation}
\fi
\iffalse
\begin{table}[t]
\centering
%\normalsize
\footnotesize
%\small
%\renewcommand{\arraystretch}{1}
\caption{Network availability for real and measured topologies}
\label{Availability}
\begin{tabular}{c|c|c|c|c|c}
\hline
&\multirow{2}{*}{Network}& \multicolumn{4}{|c}{Network Availability($\%$)} \\
\cline{3-6}
& &Naive & TBFH &  DMPA&IAC\\
\hline
\multirow{5}{*}{Real}
& CERNET2&99.93 &97.37& 98.54 & 99.93\\
\cline{2-6}
& Abilene&99.97 &97.34& 98.63& 99.97\\
\cline{2-6}
& Njlata&99.93 &96.87& 97.81& 99.93 \\
\cline{2-6}
& Toronto&99.87 &97.65& 98.74& 99.87 \\
\cline{2-6}
& Usld&99.94 &97.34& 98.57 & 99.94\\
\cline{2-6}
\hline
\multirow{5}{*}{Measured}
& AS1221 & 99.94 &97.77&98.89&99.94 \\
\cline{2-6}
& AS1239 &  99.96&96.67 &98.75&99.96 \\
\cline{2-6}
& AS1755 &  99.98&97.98&98.56&99.98 \\
\cline{2-6}
& AS3257 & 99.91&96.35&98.03&99.91 \\
\cline{2-6}
& AS3967 & 99.94 &97.89&98.79&99.94 \\
\cline{2-6}
& AS6461 & 99.96 &97.58&98.69&99.96 \\
\cline{2-6}

\hline
\end{tabular}
\end{table}
\fi
\iffalse
Fig. \ref{avtop} shows the  relationship between the network availability and the topology size.
Fig. \ref{avdeg} illustrates the relationship between the network availability and the average node degree.
As Fig. \ref{avdeg} shows, as the average node degree increase, the network availability increases too. Note that when the average node degree increases, all schemes provide better protection results, while IAC/IAC-NA and DC are always much better than DMPA and TBFH.

Table \ref{Availability} provides the network availability provided by each protection scheme, on the real and measured topologies. From the results, we can see that IAC has a clear advantage over TBFH and DMPA, and has the same performance as Naive.
\fi



\iffalse
\subsection{Incremental Deployment}
In this paper, we have proposed IAC/IAC-NA,
which is compatible with nowadays link-state routing
protocol, such as OSPF and IS-IS.
ISPs can deploy the algorithm in two ways, full deployment and incremental deployment.
However, full deployment is a burden for all ISPs.
Therefore, incremental deployment is employed in practice.
In this section, we will address the incremental deployment problem.
A node-by-node incremental deployment scheme is highly preferred.
The optimal deployment can be defined as:\\
\textbf{Optimal Deployment:}
Given a graph $G(V,E)$ and a positive integer $k$, our objective is to find a deployment $M$ where, $M \subset V$ and $|M|$=$k$ such that network availability is maximized.
\iffalse
\begin{algorithm}[h]
\caption{GreedyDeploy($G, m$)}
\label{deployment1}
\begin{algorithmic}[1]
\STATE $M\leftarrow \emptyset$
\WHILE {$|M|\leq k$}
\STATE $a\leftarrow max(B(a,M))$
\STATE $M\leftarrow M\cup \{a\}$
\ENDWHILE
\RETURN $S$
\end{algorithmic}
\end{algorithm}
\fi

We first define a benefit function for a node with respect to
the nodes which have been deployed.
Let $a$ be an arbitrary node in the network.
The benefit of node $a$ with respect to $M$, which is the nodes have been already deployed, is
denoted by $B(a,M)$, which can be expressed as:
\begin{equation}\label{benefit}
B(a,M)=A(G,M\cup \{a\})-A(G,M)
\end{equation}

It has been proved in \cite{zhang2013rpfp} that
finding the optimal deployment is NP-Complete.
Because the Optimal Deployment is NP-Complete problem.
With regard to the large $k$ and large topologies, a straight-forward
exhaustive search is computationally unacceptable.

\iffalse
A  simple greedy heuristic algorithm (GreedyDeploy)
 for selecting nodes to be deployed. The inputs of algorithm  is $k$.
The outputs of the algorithm  is the optimal deployment $M$.
The algorithm  goes through several iterations,
in each iteration, we will select a node which  has the maximum benefit to be deployed.
\fi

\iffalse
We propose an improved algorithm (SimulateDeploy) roughly modeled
after the Simulated Annealing probabilistic metaheuristic \cite{retvari2011optimizing}.
The main idea is that we first randomly select the deployed nodes set $M$.
Then finding the best $S'$
and accept it if either $S'$ can obtain lager network availability
than $S$ or  the temperature $T$ of the system is sufficiently large.
As the algorithm progresses we gradually
reduce $T$, thus the system will increasingly tend to get stuck
 in a local optimal solution.


We develop  Algorithm \ref{deployment} to solve the Optimal Deployment issue.
First, we randomly select a set of $M$, $M \subset V$ and $|M|$=$k$ , and set an initial system temperature (lines 1-2).
Let tuple $(c,c')$ be a pair of nodes such that  $c \in M$  and  $c' \notin M$,
we unconditionally accept this $c'$ either if it is
better than the previous one or if a random number generated temperature is less than $T$ (lines 4-5).
This can guarantee the algorithm escape from a local minimum.
\fi
\begin{algorithm}[h]
\caption{SimulateDeploy}
\label{deployment}
\begin{algorithmic}[1]
\STATE $T\leftarrow T_0 $
\STATE generate the initial set $M$ randomly
\REPEAT
%\STATE $\forall c \in M  and  c' \notin M$
\IF {$A(G,(M-c) \cup c')>A(G,M)\wedge T>random(T_0)$ }
\STATE $M\leftarrow (M-c) \cup c'$
\ELSE
\STATE $T\leftarrow T-1$
\ENDIF
\UNTIL{$T>T_{0}\land$ no such $(c,c')$ exists}
\RETURN $M$
\end{algorithmic}
\end{algorithm}

We propose an improved approximate algorithm roughly modeled
after the Simulated Annealing probabilistic metaheuristic \cite{retvari2011optimizing}.
The main idea is that we first select $M$, which is the solution generated randomly.
Then finding the best solutions
and accept it if either they can obtain lager network availability
than the former one or  the temperature $T$ of the system is sufficiently large.
As the algorithm progresses we gradually
reduce $T$, thus the system will increasingly tend to get stuck
in a good quality local minimum.
We develop  Algorithm \ref{deployment} to solve the Optimal Deployment issue.
The inputs of Algorithm \ref{deployment} is $k$.
The outputs of the Algorithm \ref{deployment} is the optimal deployment $M$.
First, we generate a set of $M$ for $M \subset V$ and $|M|$=$k$ randomly, and set an initial system temperature (lines 1-2).
Let tuple $(c,c')$ be a pair of nodes such that  $c \in M$  and  $c' \notin M$,
we unconditionally accept this $c'$ either if it is
better than the previous one or if a random number generated temperature is less than $T$ (lines 4-5).


Our proposed algorithm is compatible with the currently deployment intra-domain routing protocol.
In this section, we will show the relationship between the number of deployed nodes and network availability. In our experiment, we implement Algorithm \ref{deployment} respectively on real and generated topologies.
We repeated ten experiments, the final value for each topology is the average of the results.

Fig. \ref{abilene}, Fig. \ref{exodus}  and Fig. \ref{sprint} depict the relationship between the number of deployed nodes and network availability in  real networks and measured  topologies,
while Fig. \ref{top100avi} shows  the relationship between the number of deployed nodes and network availability in generated topology when the topology size is 1000.
Note that, as the node deployed ratios increases, the network availability increase too, our proposed algorithm can provide comparable performance to that of DC. Through this experiment, we will give ISPs a recommendation that they
can give priority to the deployment of some key nodes, and finally the whole network deployment.
In the actual deployment, we can give priority to the deployment of key nodes.
%We can also see that when a deployment on only 40\% nodes already increase the network availability clearly.
\fi

